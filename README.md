# Content
[[Optimal Transmission](#Optimal-Transmission)] [[GCD](#GCD)]  [[Patch Selection](#Patch-Selection)]  [[ActiveLearning](#ActiveLearning)] [[Multimodal](#Multimodal)] [[Model Merge](#Model-Merge)]

# 3D
[[2023 ICCV](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Zero-1-to-3_Zero-shot_One_Image_to_3D_Object_ICCV_2023_paper.pdf)] Zero-1-to-3: Zero-shot One Image to 3D Object  
[[2023 ICCV](https://openaccess.thecvf.com/content/ICCV2023/papers/Chan_Generative_Novel_View_Synthesis_with_3D-Aware_Diffusion_Models_ICCV_2023_paper.pdf)] Generative Novel View Synthesis with 3D-Aware Diffusion Models  
[[2023 ICML](https://proceedings.mlr.press/v202/gu23a/gu23a.pdf)] NerfDiff: Single-image View Synthesis with NeRF-guided Distillation from 3D-aware Diffusion  
[[2024 CVPR](https://arxiv.org/pdf/2401.10786)] Sat2Scene: 3D Urban Scene Generation from Satellite Images with Diffusion  
[[2024 CVPR](https://arxiv.org/pdf/2402.17427)] VastGaussian: Vast 3D Gaussians for Large Scene Reconstruction  
[[2025 CVPR](https://arxiv.org/pdf/2506.09952)] UniPre3D: Unified Pre-training of 3D Point Cloud Models with Cross-Modal Gaussian Splatting  
[[2025 TPAMI](https://arxiv.org/pdf/2507.02299)] DreamComposer++: Empowering Diffusion Models with Multi-View Conditions for 3D Content Generation  
[[2025 Arxiv](https://arxiv.org/pdf/2508.09479?)] SkySplat: Generalizable 3D Gaussian Splatting from Multi-Temporal Sparse Satellite Images   
[[2025 Arxiv](https://arxiv.org/pdf/2510.15869)] SKYFALL-GS: SYNTHESIZING IMMERSIVE 3D URBAN SCENES FROM SATELLITE IMAGERY

# Remote Sensing Image
[[2024 TGRS](https://arxiv.org/pdf/2403.11614v4)] CRS-Diff: Controllable Remote Sensing Image Generation with Diffusion Model  
[[2025 ICCV](https://arxiv.org/pdf/2509.16970)] LLM-Assisted Semantic Guidance for Sparsely Annotated Remote Sensing Object Detection  
[[2025 ICCV](https://arxiv.org/pdf/2503.06146?)] OpenRSD: Towards Open-prompts for Object Detection in Remote Sensing Images   
[[2025 ICCV]()] Active Learning Meets Foundation Models: Fast Remote Sensing Data Annotation for Object Detection   
[[2025 ICCV](https://arxiv.org/pdf/2503.06683)] Dynamic Dictionary Learning for Remote Sensing Image Segmentation   
[[2025 Arxiv](https://arxiv.org/pdf/2505.15818)] InstructSAM: A Training-Free Framework for Instruction-Oriented Remote Sensing Object Recognition  
[[2025 GIScience & Remote Sensing](https://www.tandfonline.com/doi/pdf/10.1080/15481603.2025.2543102)] Toward unsupervised building extraction from very high-resolution remote sensing images using SAM and CLIP   
[[2025 GIScience & Remote Sensing](https://arxiv.org/pdf/2410.16602)] Foundation Models for Remote Sensing and Earth Observation: A Survey   
[[2025 arXiv](https://arXiv.org/abs/2501.12931)] DynamicEarth: How Far are We from Open-Vocabulary Change Detection?  
[[2025 TGRS](https://ieeexplore.ieee.org/document/11063320)] A Unified Framework With Multimodal Fine-Tuning for Remote Sensing Semantic Segmentation  
[[2025 ICASSP](https://arXiv.org/abs/2409.00698)] Enhancing Remote Sensing Vision-Language Models for Zero-Shot Scene Classification  
[[2025 ICCV](https://arxiv.org/pdf/2411.19325)] GEOBench-VLM: Benchmarking Vision-Language Models for Geospatial Tasks  
[[2025 ICCV](https://arXiv.org/abs/2507.12857)] SCORE: Scene Context Matters in Open-Vocabulary Remote Sensing Instance Segmentation  
[[2025 ICCV](https://arXiv.org/pdf/2503.07588)] When Large Vision-Language Model Meets Large Remote Sensing Imagery: Coarse-to-Fine Text-Guided Token Pruning  
[[2025 AAAI](https://arXiv.org/abs/2412.12798)] ZoRI: Towards discriminative zero-shot remote sensing instance segmentation  
[[2024 NIPS](https://proceedings.NIPS.cc/paper_files/paper/2024/file/9415416201aa201902d1743c7e65787b-Paper-Conference.pdf)] Segment Any Change  
[[2025 CVPR](https://arXiv.org/abs/2503.23771)] XLRS-Bench: Could Your Multimodal LLMs Understand Extremely Large Ultra-High-Resolution Remote Sensing Imagery?  
[[2025 CVPR](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_Exact_Exploring_Space-Time_Perceptive_Clues_for_Weakly_Supervised_Satellite_Image_CVPR_2025_paper.pdf)] Exact: Exploring Space-Time Perceptive Clues for Weakly Supervised Satellite Image Time Series Semantic Segmentation  
[[2025 CVPR](https://arXiv.org/abs/2410.01768)] SegEarth-OV: Towards Training-Free Open-Vocabulary Segmentation for Remote Sensing Images  
[[2025 Arxiv](https://arxiv.org/abs/2508.18067)] SegEarth-OV-2: Annotation-Free Open-Vocabulary Segmentation for Remote-Sensing Images  
[[2025 AAAI](https://arxiv.org/abs/2412.19492)] Towards Open-Vocabulary Remote Sensing Image Semantic Segmentation  
[[2025 Arxiv](https://arxiv.org/pdf/2507.02294)] ViRefSAM: Visual Reference-Guided Segment Anything Model for Remote Sensing Segmentation  
[[2025 Arxiv](https://arxiv.org/pdf/2507.01573)] A Gift from the Integration of Discriminative and Diffusion-based Generative Learning: Boundary Refinement Remote Sensing Semantic Segmentation  

# instance segmentation
[[2025 Arxiv](https://arxiv.org/pdf/2507.02798)] No time to train! Training-Free Reference-Based Instance Segmentation  

# Attention
[[2025 NeurIPS](https://arxiv.org/pdf/2509.16875?)] Towards Interpretable and Efficient Attention: Compressing All by Contracting a Few  
[[2025 ICCV](https://arxiv.org/pdf/2507.12006?)] Frequency-Dynamic Attention Modulation for Dense Prediction (detail and texture)  

# Optimal Transmission
[[2021 CVPR](https://openaccess.thecvf.com/content/CVPR2021/papers/Montesuma_Wasserstein_Barycenter_for_Multi-Source_Domain_Adaptation_CVPR_2021_paper.pdf)] Wasserstein Barycenter for Multi-Source Domain Adaptation  
[[2021 ICANN](https://arxiv.org/pdf/2006.03806)] Leveraging the Feature Distribution in Transfer-based Few-Shot Learning  
[[2024 NeurIPS](https://proceedings.neurips.cc/paper_files/paper/2024/file/2d4eaf042567f1c03c086103cc154c1f-Paper-Conference.pdf)] AWT:Transferring Vision-Language Models via Augmentation, Weighting, and Transportation   
[[2025 ArXiv](https://arxiv.org/pdf/2412.00420)] TAROT- Targeted Data Selection via Optimal Transport  
[[2025 CVPR](https://openaccess.thecvf.com/content/CVPR2025/papers/Tan_Recover_and_Match_Open-Vocabulary_Multi-Label_Recognition_through_Knowledge-Constrained_Optimal_Transport_CVPR_2025_paper.pdf)] Recover and Match: Open-Vocabulary Multi-Label Recognition through Knowledge-Constrained Optimal Transport    
[[2025 ICCV](https://arxiv.org/pdf/2506.23822)] Interpretable Zero-Shot Learning with Locally-Aligned Vision-Language Model

-----------------------------------------------------------------------------------------------
# Patch Selection
[[2021 CVPR](https://openaccess.thecvf.com/content/CVPR2021/papers/Cordonnier_Differentiable_Patch_Selection_for_Image_Recognition_CVPR_2021_paper.pdf)] Differentiable Patch Selection for Image Recognition   
[[2022 CVPR](https://arxiv.org/pdf/2112.07658)] A-ViT: Adaptive Tokens for Efficient Vision Transformer    
[[2022 ICLR](https://arxiv.org/pdf/2202.07800)] EVit:NOT ALL PATCHES ARE WHAT YOU NEED:EXPEDITING VISION TRANSFORMERS VIA TOKEN REORGANIZATIONS   
[[2023 ICLR](https://arxiv.org/pdf/2210.13007)] ITERATIVE PATCH SELECTION FOR HIGH-RESOLUTION IMAGE RECOGNITION   
[[2023 I/ECCV](https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Less_is_More_Focus_Attention_for_Efficient_DETR_ICCV_2023_paper.pdf)] Less is More: Focus Attention for Efficient DETR   
[[2023 AJCAI](https://arxiv.org/abs/2310.05654)] IdleViT: Efficient Vision Transformer via Token Idle and Token Cut Loss    
[[2024 ArXiv](https://arxiv.org/pdf/2412.00965)] Token Cropr: Faster ViTs for Quite a Few Tasks    
[[2024 AAAI](https://arxiv.org/pdf/2412.14598)] Can We Get Rid of Handcrafted Feature Extractors? SparseViT: Nonsemantics-Centered, Parameter-Efficient Image Manipulation Localization through Spare-Coding Transformer   
[[2024 NeurIPS](https://openreview.net/pdf?id=pVPyCgXv57)] Learning to Merge Tokens via Decoupled Embedding for Efficient Vision Transformers   
[[2024 CVPR](https://openaccess.thecvf.com/content/CVPR2024/papers/Luo_Learning_to_Rank_Patches_for_Unbiased_Image_Redundancy_Reduction_CVPR_2024_paper.pdf)] Learning to Rank Patches for Unbiased Image Redundancy Reduction   
[[2024 CVPR](https://openaccess.thecvf.com/content/CVPR2024/papers/Fu_Linguistic-Aware_Patch_Slimming_Framework_for_Fine-grained_Cross-Modal_Alignment_CVPR_2024_paper.pdf)] Linguistic-Aware Patch Slimming Framework for Fine-grained Cross-Modal Alignment   
[[2025 ICLR](https://arxiv.org/pdf/2502.18137)] SpargeAttn: Accurate Sparse Attention Accelerating Any Model Inference      
[[2025 CVPR](https://openaccess.thecvf.com/content/CVPR2025/papers/Qin_No_Pains_More_Gains_Recycling_Sub-Salient_Patches_for_Efficient_High-Resolution_CVPR_2025_paper.pdf)] No Pains, More Gains: Recycling Sub-Salient Patches for Efficient High-Resolution Image Recognition   
[[2025 ICCV](https://iccv.thecvf.com/virtual/2025/poster/2161)] METEOR: Multi-Encoder Collaborative Token Pruning for Efficient Vision Language Models  
[[2025 Arxiv](https://arxiv.org/pdf/2410.14729)] Is Less More? Exploring Token Condensation as Training-free Test-time Adaptation    
[[2025 Arxiv]([https://arxiv.org/pdf/2410.14729](https://arxiv.org/pdf/2503.21817))] Skip-Vision: Efficient and Scalable Acceleration of Vision-Language Models via
 Adaptive Token Skipping    
[[2025 Arxiv](https://arxiv.org/pdf/2405.13337?)] Semantic Equitable Clustering: A Simple and Effective Strategy for Clustering Vision Tokens  

-----------------------------------------------------------------------------------------------
# Large Model Finetune & zero/few-shot
[[2020 ICML](https://proceedings.mlr.press/v119/ziko20a/ziko20a.pdf)] Laplacian Regularized Few-Shot Learning     
[[2021 ICML](https://proceedings.mlr.press/v139/cui21a/cui21a.pdf)] Parameterless Transductive Feature Re-representation for Few-Shot Learning   
[[2021 I/ECCV](https://openaccess.thecvf.com/content/ICCV2021/papers/Lazarou_Iterative_Label_Cleaning_for_Transductive_and_Semi-Supervised_Few-Shot_Learning_ICCV_2021_paper.pdf)] Iterative label cleaning for transductive and semi-supervised few-shot learning  
[[2022 CVPR](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_EASE_Unsupervised_Discriminant_Subspace_Learning_for_Transductive_Few-Shot_Learning_CVPR_2022_paper.pdf)] EASE: Unsupervised Discriminant Subspace Learning for Transductive Few-Shot Learning  
[[2023 I/ECCV](https://openaccess.thecvf.com/content/ICCV2023/papers/Hao_Class-Aware_Patch_Embedding_Adaptation_for_Few-Shot_Image_Classification_ICCV_2023_paper.pdf)] Class-Aware Patch Embedding Adaptation for Few-Shot Image Classification   
[[2023 I/ECCV](https://openaccess.thecvf.com/content/ICCV2023/papers/Tian_Prototypes-oriented_Transductive_Few-shot_Learning_with_Conditional_Transport_ICCV_2023_paper.pdf)] Prototypes-oriented Transductive Few-shot Learning with Conditional Transport   
[[2023 I/ECCV](https://openaccess.thecvf.com/content/ICCV2023/papers/Ouali_Black_Box_Few-Shot_Adaptation_for_Vision-Language_Models_ICCV_2023_paper.pdf)] Black Box Few-Shot Adaptation for Vision-Language models    
[[2023 CVPR](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhu_Transductive_Few-Shot_Learning_With_Prototype-Based_Label_Propagation_by_Iterative_Graph_CVPR_2023_paper.pdf)] Transductive Few-shot Learning with Prototype-based Label Propagation by Iterative Graph Refinement   
[[2023 NeurIPS](https://proceedings.neurips.cc/paper_files/paper/2023/file/bf85879363044ca21f7868a3d1b4021c-Paper-Conference.pdf)] Enhancing CLIP with CLIP: Exploring Pseudolabeling for Limited-Label Prompt Tuning  
[[2023 NeurIPS](https://arxiv.org/pdf/2305.18287)] LaFTer: Label-Free Tuning of Zero-shot Classifier using Language and Unlabeled Image Collections    
[[2024 ICML](https://arxiv.org/pdf/2406.10502)] Candidate Pseudolabel Learning   
[[2024 ICML](https://arxiv.org/pdf/2405.11756)] Erasing the Bias: Fine-Tuning Foundation Models for Semi-Supervised Learning   
[[2024 ICML](https://arxiv.org/pdf/2402.04050)] Connecting the Dots: Collaborative Fine-tuning for Black-Box Vision-Language Models  
[[2024 ICML](https://arxiv.org/pdf/2402.04087)] A Hard-to-Beat Baseline for Training-free CLIP-Based Adaptation   
[[2024 NeurIPS](https://arxiv.org/pdf/2406.01837)] Boosting Vision-Language Models with Transduction   
[[2024 Arxiv](https://arxiv.org/pdf/2407.16977)] Selective Vision-Language Subspace Projection for Few-shot CLIP    
[[2024 NeurIPS](https://arxiv.org/pdf/2410.13016)] Interpreting and Analyzing CLIP’s Zero-Shot Image Classification via Mutual Knowledge    
[[2024 NeurIPS](https://proceedings.neurips.cc/paper_files/paper/2024/file/6af08ba9468f0daca4b8dd388cb95824-Paper-Conference.pdf)] Vision-Language Models are Strong Noisy Label Detectors  
[[2024 CVPR](https://openaccess.thecvf.com/content/CVPR2024/papers/Ma_Improved_Self-Training_for_Test-Time_Adaptation_CVPR_2024_paper.pdf)] Improved Self-Training for Test-Time Adaptation  
[[2024 CVPR](https://openaccess.thecvf.com/content/CVPR2024/papers/Zanella_On_the_Test-Time_Zero-Shot_Generalization_of_Vision-Language_Models_Do_We_CVPR_2024_paper.pdf)] On the test-time zero-shot generalization of vision-language models: Do wereally need prompt learning?   
[[2024 CVPR](https://openaccess.thecvf.com/content/CVPR2024/papers/Martin_Transductive_Zero-Shot_and_Few-Shot_CLIP_CVPR_2024_paper.pdf)] Transductive Zero-Shot and Few-Shot CLIP    
[[2024 NeurIPS](https://arxiv.org/pdf/2404.08461)] OTTER: Effortless Label Distribution Adaptation of Zero-shot Models   
[[2024 NeurIPS](https://arxiv.org/pdf/2405.18330)] Frustratingly Easy Test-Time Adaptation of Vision-Language Models  
[[2024 NeurIPS](https://proceedings.neurips.cc/paper_files/paper/2024/file/38b787fc530d0b31825827e2cc306656-Paper-Conference.pdf)] Dual Prototype Evolving for Test-Time Generalization of Vision-Language Models  
[[2024 Arxiv](https://arxiv.org/pdf/2403.13805.pdf)] RAR: Retrieving And Ranking Augmented MLLMs for Visual Recognition   
[[2025 IETIP](https://ieeexplore.ieee.org/abstract/document/10925517)] Task-to-Instance Prompt Learning for Vision-Language Models at Test Time     
[[2025 CVPR](https://arxiv.org/pdf/2412.16739)] UNEM: UNrolled Generalized EM for Transductive Few-Shot Learning     
[[2025 CVPR](https://arxiv.org/abs/2503.23388)] COSMIC: Clique-Oriented Semantic Multi-space Integration for Robust CLIP Test-Time Adaptation  
[[2025 CVPR](https://arxiv.org/pdf/2504.12104)] Logits DeConfusion with CLIP for Few-Shot Learning  
[[2025 CVPR](https://arxiv.org/pdf/2501.11175 )] ProKeR: A Kernel Perspective on Few-Shot Adaptation of Large Vision-Language Models  
[[2025 CVPR](https://openaccess.thecvf.com/content/CVPR2025/papers/Zanella_Realistic_Test-Time_Adaptation_of_Vision-Language_Models_CVPR_2025_paper.pdf)] Realistic Test-Time Adaptation of Vision-Language Models   
[[2025 CVPR](https://arxiv.org/pdf/2505.24693)] Conformal Prediction for Zero-Shot Models  
[[2025 Arxiv](https://arxiv.org/pdf/2411.19346)] CLIP meets DINO for Tuning Zero-Shot Classifier using Unlabeled Image Collections   
[[2025 Arxiv](https://arxiv.org/pdf/2506.04005)] Vocabulary-free few-shot learning for Vision-Language Models  
[[*2025 CVPR]()] Surrogate Prompt Learning: Towards Efficient and Diverse Prompt Learning for Vision-Language Models   
[[2025 ICML](https://arxiv.org/pdf/2506.02557)] Kernel-based Unsupervised Embedding Alignment for Enhanced Visual Representation in Vision-language Models   
[[2025 ICML](https://arxiv.org/pdf/2505.13233?)] From Local Details to Global Context: Advancing Vision-Language Models with Attention-Based Selection   
[[2025 ICML](https://openreview.net/pdf?id=tra8ktyk0E)] Dynamic Similarity Graph Construction with Kernel Density Estimation    
[[2025 AAAI](https://ojs.aaai.org/index.php/AAAI/article/view/32534/34689)] Text and Image Are Mutually Benefcial: Enhancing Training-Free Few-Shot Classifcation with CLIP  
[[2025 CVPR](https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_Enhancing_Few-Shot_Class-Incremental_Learning_via_Training-Free_Bi-Level_Modality_Calibration_CVPR_2025_paper.pdf)] Enhancing Few-Shot Class-Incremental Learning via Training-Free Bi-Level Modality Calibration   
[[2025 CVPR](https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_SEC-PromptSEmantic_Complementary_Prompting_for_Few-Shot_Class-Incremental_Learning_CVPR_2025_paper.pdf)] SEC-Prompt:SEmantic Complementary Prompting for Few-Shot Class-Incremental Learning   
[[2025 CVPR](https://openaccess.thecvf.com/content/CVPR2025/papers/Yang_ImagineFSL_Self-Supervised_Pretraining_Matters_on_Imagined_Base_Set_for_VLM-based_CVPR_2025_paper.pdf)] ImagineFSL: Self-Supervised Pretraining Matters on Imagined Base Set for VLM-based Few-shot Learning   
[[2025 CVPR](https://openaccess.thecvf.com/content/CVPR2025/papers/Nandam_Text_Augmented_Correlation_Transformer_For_Few-shot_Classification__Segmentation_CVPR_2025_paper.pdf)]  Text Augmented Correlation Transformer For Few-shot Classification & Segmentation  
[[2025 ICLR](https://arxiv.org/pdf/2412.18303)] EFFICIENT AND CONTEXT-AWARE LABEL PROPAGA TION FOR ZERO-/FEW-SHOT TRAINING-FREE ADAP TATION OF VISION-LANGUAGE MODEL   
[[2025 ICCV](https://arxiv.org/pdf/2507.20834?)] Rethinking Few Shot CLIP Benchmarks: A Critical Analysis in the Inductive Setting   
[[2025 Arxiv](https://arxiv.org/pdf/2505.23745)] To Trust Or Not To Trust Your Vision-Language Model’s Prediction   
[[2025 Arxiv](https://arxiv.org/pdf/2508.03102)] Causal Disentanglement and Cross-Modal Alignment for Enhanced Few-Shot Learning  
[[2025 *]] Hierarchical Divide-and-Conquer Grouping for Classification Adaptation of Pre-Trained Models  


-----------------------------------------------------------------------------------------------
# ActiveLearning
[[2006](https://link.springer.com/chapter/10.1007/11871842_40)] Margin-Based Active Learning for Structured Output Spaces   
[[2018](https://arxiv.org/pdf/1708.00489)] ACTIVE LEARNING FOR CONVOLUTIONAL NEURAL NETWORKS: A CORE-SET APPROACH   
[[2019](https://arxiv.org/pdf/1905.03677)] Learning Loss for Active Learning   
[[2020 ICLR](https://arxiv.org/pdf/1906.03671)] DEEP BATCH ACTIVE LEARNING BY DIVERSE, UNCERTAIN GRADIENT LOWER BOUNDS   
[[2023 CVPR](https://openaccess.thecvf.com/content/CVPR2023/papers/Xie_Active_Finetuning_Exploiting_Annotation_Budget_in_the_Pretraining-Finetuning_Paradigm_CVPR_2023_paper.pdf)] Active Finetuning: Exploiting Annotation Budget in the Pretraining-Finetuning Paradigm      
[[2023 NeurIPS](https://proceedings.neurips.cc/paper_files/paper/2023/file/047682108c3b053c61ad2da5a6057b4e-Paper-Conference.pdf)] Towards Free Data Selection with General-Purpose Models    
[[2024 NeurIPS](https://github.com/Thinklab-SJTU/BiLAF)] Boundary Matters: A Bi-Level Active Finetuning Framework   
[[2024 CVPR](https://arxiv.org/pdf/2311.07634)][[code](https://github.com/VincentXu521/ActiveDC/tree/master)] ActiveDC: Distribution Calibration for Active Finetuning   
[[2024 CVPR](https://arxiv.org/pdf/2403.04272)] Active Generalized Category Discovery   
[[2024 CVPR](https://arxiv.org/pdf/2311.11178v3)] Active Prompt Learning in Vision Language Models   
[[2024 Arxiv](https://arxiv.org/pdf/2411.16722)] Active Prompt Learning with Vision-Language Model Priors  
[[2024 I/ECCV](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/07212.pdf)] Labeled Data Selection for Category Discovery      
[[2025 ICLR](https://arxiv.org/pdf/2410.11215)][[code](https://github.com/Jackbrocp/clip-powered-data-selection)] a clip-power framework for robust and generalizable data selection   
[[2025 ICLR](https://arxiv.org/pdf/2406.04273)] ELFS: LABEL-FREE CORESET SELECTION WITH PROXY TRAINING DYNAMICS   
[[2025 Arxiv](https://arxiv.org/pdf/2502.08227)] Enhancing Sample Selection by Cutting Mislabeled Easy Examples    
[[*2025 ICML]()] Foundation Model insights and a Multi-model Approach for Superior Fine-grained One-shot Subset Selection   
[[2025 ArXiv](https://arxiv.org/pdf/2412.00420)] TAROT- Targeted Data Selection via Optimal Transport   
[[*2025 ICML]()]The Best of Both Worlds: Bridging Quality and Diversity in Data Selection with Bipartite Graph   
[[*2025]()] To Label or Not to Label: PALM – A Predictive Model for Evaluating Sample Efficiency in Active Learning Models

-----------------------------------------------------------------------------------------------
# Multimodal
[[2023](https://arxiv.org/pdf/2308.12966)] Qwen-VL: AVersatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond    
[[2023](http://arxiv.org/abs/2311.04257)] mPLUG-Owl2: Revolutionizing Multi-modal Large Language Model with Modality Collaboration   
[[2023 NeurIPS](https://arxiv.org/pdf/2305.14381)] Connecting Multi-modal Contrastive Representations   
[[2024](https://arxiv.org/pdf/2410.05160)] VLM2VEC: training vision-language models for massive multimodal embedding tasks   
[[2024 CVPR](https://openaccess.thecvf.com/content/CVPR2024/papers/Guo_CrossMAE_Cross-Modality_Masked_Autoencoders_for_Region-Aware_Audio-Visual_Pre-Training_CVPR_2024_paper.pdf)] CrossMAE: Cross-Modality Masked Autoencoders for Region-Aware Audio-Visual Pre-Training   
[[2024 CVPR](https://openaccess.thecvf.com/content/CVPR2024/papers/Tong_Eyes_Wide_Shut_Exploring_the_Visual_Shortcomings_of_Multimodal_LLMs_CVPR_2024_paper.pdf)]  Eyes Wide Shut? Exploring the Visual Shortcomings of Multimodal LLMs   
[[2024 NeurIPS](https://arxiv.org/pdf/2411.03978?)] Customized Multiple Clustering via Multi-Modal Subspace Proxy Learning  
[[2024 NeurIPS](https://arxiv.org/pdf/2310.08884)] Extending Multi-modal Contrastive Representations    
[[2024 NeurIPS](https://arxiv.org/pdf/2411.06921)] UMFC: Unsupervised Multi-Domain Feature Calibration for Vision-Language Models   
[[2024 WACV](https://arxiv.org/pdf/2408.08855)] DPA: Dual Prototypes Alignment for Unsupervised Adaptation of Vision-Language Models  
[[2024 CVPR H](https://arxiv.org/pdf/2311.06607)] ImageResolutionandText Label Are Important Things for Large Multi-modal Models    
[[2025 ArXiv](https://arxiv.org/pdf/2504.12717)] Post-pre-training for Modality Alignment in Vision-Language Foundation Models   
[[2025 CVPR](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_DH-Set_Improving_Vision-Language_Alignment_with_Diverse_and_Hybrid_Set-Embeddings_Learning_CVPR_2025_paper.pdf)] DH-Set: Improving Vision-Language Alignment with Diverse and Hybrid Set-Embeddings Learning    
[[2025 ICCV](https://arxiv.org/abs/2503.08497)] MMRL: Multi-Modal Representation Learning for Vision-Language Models

-----------------------------------------------------------------------------------------------
# Model Merge
[[2025 CVPR](https://openaccess.thecvf.com/content/CVPR2025/papers/Wang_DeCLIP_Decoupled_Learning_for_Open-Vocabulary_Dense_Perception_CVPR_2025_paper.pdf)] DeCLIP: Decoupled Learning for Open-Vocabulary Dense Perception   
[[2025 CVPR H](http://arxiv.org/abs/2504.03193)] Mamba as a Bridge: Where Vision Foundation Models Meet Vision Language Models for Domain-Generalized Semantic Segmentation   
[[2025 ArXiv](https://arxiv.org/pdf/2506.02557)] Kernel-based Unsupervised Embedding Alignment for Enhanced Visual Representation in Vision-language Models  
[[2025 Arxiv](https://arxiv.org/pdf/2411.19346)] CLIP meets DINO for Tuning Zero-Shot Classifier using Unlabeled Image Collections    
[[2025 Arxiv](https://arxiv.org/pdf/2506.16506)] Subspace-Boosted Model Merging    
[[2025 ICML](https://arxiv.org/pdf/2506.06231?)] Towards an Explainable Comparison and Alignment of Feature Embeddings


-----------------------------------------------------------------------------------------------

# Classification & Semantic Segmentation
[[2023 NeurIPS](https://proceedings.neurips.cc/paper_files/paper/2023/file/619cbddb92b8c6fecaf2b86463153be9-Paper-Conference.pdf)] Vocabulary-free Image Classification  
[[2024 Arxiv](https://arxiv.org/pdf/2404.10864)] Vocabulary-free Image Classification and Semantic Segmentation   
[[2025 CVPR](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_Interpretable_Image_Classification_via_Non-parametric_Part_Prototype_Learning_CVPR_2025_paper.pdf)] Interpretable Image Classification via Non-parametric Part Prototype Learning

----------------------------------------------------------------------------------------------
# 3D point cloud
[[2025 Arxiv](https://arxiv.org/pdf/2506.22375)] Exploiting Vision Language Model for Training-Free 3D Point Cloud OOD Detection via Graph Score Propagation  

----------------------------------------------------------------------------------------------
# mul-model 
[[2025 ArXiv](https://arxiv.org/pdf/2506.18504)]  Generalizing Vision-Language Models to Novel Domains: A Comprehensive Survey   

----------------------------------------------------------------------------------------------
# Multiple Instance Learning
[[2025 Arxiv](https://arxiv.org/pdf/2507.08711)] SGPMIL: Sparse Gaussian Process Multiple Instance Learning   

-----------------------------------------------------------------------------------------------
# Writing
[[2025 Arxiv](https://arxiv.org/pdf/2411.19346)] CLIP meets DINO for Tuning Zero-Shot Classifier using Unlabeled Image Collections  
[[2025 ArXiv](https://arxiv.org/pdf/2505.02056)] Handling Imbalanced Pseudolabels for Vision-Language Models with Concept Alignment and Confusion-Aware Calibrated Margin   
[[2025 CVPR H](http://arxiv.org/abs/2504.03193)] Mamba as a Bridge: Where Vision Foundation Models Meet Vision Language Models for Domain-Generalized Semantic Segmentation   
[[2025 CVPR](https://arxiv.org/abs/2503.23388)] COSMIC: Clique-Oriented Semantic Multi-space Integration for Robust CLIP Test-Time Adaptation  

# Waiting 
PRISM: Reducing Spurious Implicit Biases in Vision-Language Models with LLM-Guided Embedding Projection  
Enhancing Few-Shot Vision-Language Classification with Large Multimodal Model Features    
Target Bias Is All You Need: Zero-Shot Debiasing of Vision-Language Models with Bias Corpus  
Dynamic Multimodal Prototype Learning in Vision-Language Models   
Hierarchical Divide-and-Conquer Grouping for Classification Adaptation of Pre-Trained Models  


-----------------------------------------------------------------------------------------------
# GCD
[[2023 I/ECCV](https://arxiv.org/pdf/2305.06144)] Learning Semi-supervised Gaussian Mixture Models for Generalized Category Discovery    
[[2023 NeruIPS](https://proceedings.neurips.cc/paper_files/paper/2023/file/3f52ab4322e967efd312c38a68d07f01-Paper-Conference.pdf)] No Representation Rules Them All in Category Discovery   
[[2024 I/ECCV](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/08177.pdf)] Learning to Distinguish Samples for Generalized Category Discovery  
[[2024 I/ECCV](https://www.arxiv.org/abs/2408.14371)] SelEx: Self-Expertise in Fine-Grained Generalized Category Discovery  
[[2024 CVPR](https://openaccess.thecvf.com/content/CVPR2024/papers/Xiao_Targeted_Representation_Alignment_for_Open-World_Semi-Supervised_Learning_CVPR_2024_paper.pdf)] Targeted Representation Alignment for Open-World Semi-Supervised Learning   
[[2024 CVPR](https://openaccess.thecvf.com/content/CVPR2024/papers/Fu_Linguistic-Aware_Patch_Slimming_Framework_for_Fine-grained_Cross-Modal_Alignment_CVPR_2024_paper.pdf)] Linguistic-Aware Patch Slimming Framework for Fine-grained Cross-Modal Alignment   
[[2024 NeruIPS](https://arxiv.org/pdf/2411.01833)] OwMatch: Conditional Self-Labeling with Consistency for Open-World Semi-Supervised Learning    
[[2025 ICLR](https://openreview.net/pdf?id=On8E0U9vbz)] GENERALIZED CATEGORY DISCOVERY UTILIZING RECIPROCAL LEARNING AND CLASS-WISE DISTRIBUTION REGULARIZATION   
[[2024 ArXiv](https://arxiv.org/pdf/2409.11624)] Multimodal Generalized Category Discovery   
[[2025 CVPR](https://arxiv.org/pdf/2403.09974)] Unlocking the Multi-modal Potential of CLIP for Generalized Category Discovery   
[[2025 CVPR](https://arxiv.org/abs/2503.12035)] MOS: Modeling Object-Scene Associations in Generalized Category Discovery (CVPR 2025)  
[[2025 ArXiv](https://arxiv.org/pdf/2502.09501)] Prior-Constrained Association Learning for Fine-Grained Generalized Category Discovery  
[[2025 ArXiv](https://arxiv.org/pdf/2503.16782)] Learning Part Knowledge to Facilitate Category Understanding for Fine-Grained Generalized Category Discovery  
[[2025 ArXiv](https://arxiv.org/pdf/2502.09501)] Prior-Constrained Association Learning for Fine-Grained Generalized Category Discovery   
[[2025 Arxiv](https://arxiv.org/pdf/2503.14500)] Utilization of Neighbor Information for Image Classification with Different Levels of Supervision  
[[2025 Arixv](https://openreview.net/pdf?id=On8E0U9vbz)] GENERALIZED CATEGORY DISCOVERY UTILIZING RECIPROCAL LEARNING AND CLASS-WISE DISTRIBUTION REGULARIZATION   
[[2025 CVPR](https://openaccess.thecvf.com/content/CVPR2025/papers/Zhang_Less_Attention_is_More_Prompt_Transformer_for_Generalized_Category_Discovery_CVPR_2025_paper.pdf)] Less Attention is More: Prompt Transformer for Generalized Category Discovery    
[[2025 CVPR](https://openaccess.thecvf.com/content/CVPR2025/papers/Liu_Hyperbolic_Category_Discovery_CVPR_2025_paper.pdf)] Hyperbolic Category Discovery   
[[2025 Arixv](https://arxiv.org/pdf/2506.17232)] PCaM: A Progressive Focus Attention-Based Information Fusion Method for Improving Vision Transformer Domain Adaptation  
[[2025 Arxiv](https://arxiv.org/pdf/2507.01711)] Component Adaptive Clustering for Generalized Category Discovery  
 
