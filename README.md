# Content
[[LightWeight](#LightWeight)] [[Grounding](#Grounding)] [[Visual Place Recognition](#Visual-Place-Recognition)] [[Patch Selection](#Patch-Selection)] [[Medical](#Medical)] [[Action Recognition](#Action-Recognition)] [[ReID](#ReID)] [[GCD](#GCD)] [[Affective Computing](#Affective-Computing)] [[ActiveLearning](#ActiveLearning)] [[Label Selection](#Label-Selection)] [[Multimodal](#Multimodal)] [[zero & few shot](#zero-few-shot)] [[Model Merging](#Model-Merging)] [[Representation Learning](#Representation-Learning)] [[Instance Retrieval](#Instance-Retrieval)] [[Clustering](#Clustering)] [[semantic segmentation](#semantic-segmentation)] [[Optimal Transportation](#Optimal-Transportation)]

## LightWeight
[CVPR 2022]A-ViT: Adaptive Tokens for Efficient Vision Transformer [(https://arxiv.org/pdf/2112.07658)]  
[2025]SpargeAttn: Accurate Sparse Attention Accelerating Any Model Inference [(https://arxiv.org/pdf/2502.18137)]

## Grounding
Spatial-Aware Token for Weakly Supervised Object Localization [[ICCV2023](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Spatial-Aware_Token_for_Weakly_Supervised_Object_Localization_ICCV_2023_paper.pdf)]   
PIN:Positional Insert Unlocks Object Localisation Abilities in VLMs [[CVPR](https://openaccess.thecvf.com/content/CVPR2024/papers/Dorkenwald_PIN_Positional_Insert_Unlocks_Object_Localisation_Abilities_in_VLMs_CVPR_2024_paper.pdf)]  
Language-driven Grasp Detection[[CVPR 2024](https://openaccess.thecvf.com/content/CVPR2024/papers/Vuong_Language-driven_Grasp_Detection_CVPR_2024_paper.pdf)]   
Multi-task Visual Grounding with Coarse-to-Fine Consistency Constraints [[2025](https://arxiv.org/pdf/2501.06710)]  

## Visual Place Recognition
NetVLAD: CNNarchitecture for weakly supervised place recognition [[CVPR 2016](https://openaccess.thecvf.com/content_cvpr_2016/papers/Arandjelovic_NetVLAD_CNN_Architecture_CVPR_2016_paper.pdf)]  
Optimal Transport Aggregation for Visual Place Recognition [[CVPR 2024](https://arxiv.org/pdf/2311.15937)]  

## Patch Selection
Differentiable Patch Selection for Image Recognition [[CVPR 2021](https://openaccess.thecvf.com/content/CVPR2021/papers/Cordonnier_Differentiable_Patch_Selection_for_Image_Recognition_CVPR_2021_paper.pdf)]  
EVit:NOT ALL PATCHES ARE WHAT YOU NEED:EXPEDITING VISION TRANSFORMERS VIA TOKEN REORGANIZATIONS [[ICLR2022](https://arxiv.org/pdf/2202.07800)]  
IdleViT: Efficient Vision Transformer via Token Idle and Token Cut Loss [[AJCAI 2023](https://arxiv.org/abs/2310.05654)]  
Less is More: Focus Attention for Efficient DETR [[ICCV 2023] (https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Less_is_More_Focus_Attention_for_Efficient_DETR_ICCV_2023_paper.pdf)]  
ITERATIVE PATCH SELECTION FOR HIGH-RESOLUTION IMAGE RECOGNITION [[ICLR 2023](https://arxiv.org/pdf/2210.13007)]  
IdleViT: Efficient Vision Transformer via Token Idle and Token Cut Loss [[AJCAI23](https://arxiv.org/pdf/2310.05654)]  
Learning to Merge Tokens via Decoupled Embedding for Efficient Vision Transformers [[NeurIPS 2024](https://openreview.net/pdf?id=pVPyCgXv57)]  
Token Cropr: Faster ViTs for Quite a Few Tasks [[2024](https://arxiv.org/pdf/2412.00965)]  
Can We Get Rid of Handcrafted Feature Extractors? SparseViT: Nonsemantics-Centered, Parameter-Efficient Image Manipulation Localization through Spare-Coding Transformer [[2024](https://arxiv.org/pdf/2412.14598)]  
Learning to Rank Patches for Unbiased Image Redundancy Reduction [[CVPR 2024](https://openaccess.thecvf.com/content/CVPR2024/papers/Luo_Learning_to_Rank_Patches_for_Unbiased_Image_Redundancy_Reduction_CVPR_2024_paper.pdf)]  
Linguistic-Aware Patch Slimming Framework for Fine-grained Cross-Modal Alignment [[CVPR 2024](https://openaccess.thecvf.com/content/CVPR2024/papers/Fu_Linguistic-Aware_Patch_Slimming_Framework_for_Fine-grained_Cross-Modal_Alignment_CVPR_2024_paper.pdf)]  

## Medical 
Multiple Instance Learning Framework with Masked Hard Instance Mining for Whole Slide Image Classification [[ICCV 2023](https://arxiv.org/pdf/2307.15254)]  
Pseudo-Bag Mixup Augmentation for Multiple Instance Learning-Based Whole Slide Image Classification [[Trans MI 2024](https://arxiv.org/pdf/2306.16180)]  
A visual-language foundation model for computational pathology [Nature medicine]  
Transcriptomics-guided Slide Representation Learning in Computational Pathology [[CVPR 2024](https://openaccess.thecvf.com/content/CVPR2024/papers/Jaume_Transcriptomics-guided_Slide_Representation_Learning_in_Computational_Pathology_CVPR_2024_paper.pdf)]  

## Action Recognition
Part-aware Unified Representation of Language and Skeleton for Zero-shot Action Recognition [[CVPR 2024](https://openaccess.thecvf.com/content/CVPR2024/papers/Zhu_Part-aware_Unified_Representation_of_Language_and_Skeleton_for_Zero-shot_Action_CVPR_2024_paper.pdf)]

## ReID
A Pedestrian is Worth One Prompt: Towards Language Guidance Person Re-Identification [[CVPR 2024](https://openaccess.thecvf.com/content/CVPR2024/papers/Yang_A_Pedestrian_is_Worth_One_Prompt_Towards_Language_Guidance_Person_CVPR_2024_paper.pdf)]  

## Affective Computing
Most Important Person-guided Dual-branch Cross-Patch Attention for Group Affect Recognition [[ICCV 2023](https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_Most_Important_Person-Guided_Dual-Branch_Cross-Patch_Attention_for_Group_Affect_Recognition_ICCV_2023_paper.pdf)]  

## GCD
Learning Semi-supervised Gaussian Mixture Models for Generalized Category Discovery [[2023](https://arxiv.org/pdf/2305.06144)]  
Targeted Representation Alignment for Open-World Semi-Supervised Learning [[2024 CVPR](https://openaccess.thecvf.com/content/CVPR2024/papers/Xiao_Targeted_Representation_Alignment_for_Open-World_Semi-Supervised_Learning_CVPR_2024_paper.pdf)]  
Unlocking the Multi-modal Potential of CLIP for Generalized Category Discovery [[2024](https://arxiv.org/pdf/2403.09974)]  
OwMatch: Conditional Self-Labeling with Consistency for Open-World Semi-Supervised Learning [[2024](https://arxiv.org/pdf/2411.01833)]  
multimodal generalized category discovery [[2024](https://arxiv.org/pdf/2409.11624)]  
* Linguistic-Aware Patch Slimming Framework for Fine-grained Cross-Modal Alignment [[CVPR 2024](https://openaccess.thecvf.com/content/CVPR2024/papers/Fu_Linguistic-Aware_Patch_Slimming_Framework_for_Fine-grained_Cross-Modal_Alignment_CVPR_2024_paper.pdf)]  
* Learning to Distinguish Samples for Generalized Category Discovery [[2024 ECCV](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/08177.pdf)]
* Prior-Constrained Association Learning for Fine-Grained Generalized Category Discovery [[2025](https://arxiv.org/pdf/2502.09501)]  

## ActiveLearning
Margin-Based Active Learning for Structured Output Spaces [[2006](https://link.springer.com/chapter/10.1007/11871842_40)]  
ACTIVE LEARNING FOR CONVOLUTIONAL NEURAL NETWORKS: A CORE-SET APPROACH [[2018](https://arxiv.org/pdf/1708.00489)]  
Learning Loss for Active Learning [[2019](https://arxiv.org/pdf/1905.03677)]  
DEEP BATCH ACTIVE LEARNING BY DIVERSE, UNCERTAIN GRADIENT LOWER BOUNDS [[ICLR2020](https://arxiv.org/pdf/1906.03671)]  
Active Finetuning: Exploiting Annotation Budget in the Pretraining-Finetuning Paradigm [[2023 CVPR](https://openaccess.thecvf.com/content/CVPR2023/papers/Xie_Active_Finetuning_Exploiting_Annotation_Budget_in_the_Pretraining-Finetuning_Paradigm_CVPR_2023_paper.pdf)]  
Boundary Matters: A Bi-Level Active Finetuning Framework [[2024](https://arxiv.org/pdf/2403.10069)]  
ActiveDC: Distribution Calibration for Active Finetuning [[CVPR 2024](https://arxiv.org/pdf/2311.07634)][[code](https://github.com/VincentXu521/ActiveDC/tree/master)]  
Active Generalized Category Discovery [[2024 CVPR](https://arxiv.org/pdf/2403.04272)]  
Active Prompt Learning in Vision Language Models [[2024 CVPR](https://arxiv.org/pdf/2311.11178v3)]  
Active Prompt Learning with Vision-Language Model Priors [[2024](https://arxiv.org/pdf/2411.16722)]

## Label Selection
Towards Free Data Selection with General-Purpose Models  [[2023 NeurIPS](https://proceedings.neurips.cc/paper_files/paper/2023/file/047682108c3b053c61ad2da5a6057b4e-Paper-Conference.pdf)]  
Labeled Data Selection for Category Discovery [[2024 ECCV](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/07212.pdf)]  
a clip-power framework for robust and generalizable data selection [[2024](https://arxiv.org/pdf/2410.11215)]  
Enhancing Sample Selection by Cutting Mislabeled Easy Examples [[2025](https://arxiv.org/pdf/2502.08227)]  

## Multimodal
Qwen-VL: AVersatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond  [[2023](https://arxiv.org/pdf/2308.12966)]  
mPLUG-Owl2: Revolutionizing Multi-modal Large Language Model with Modality Collaboration [[2023](http://arxiv.org/abs/2311.04257)]  
Connecting Multi-modal Contrastive Representations [[NeurIPS 2023](https://arxiv.org/pdf/2305.14381)]  
VLM2VEC: training vision-language models for massive multimodal embedding tasks [[2024](https://arxiv.org/pdf/2410.05160)]  
CrossMAE: Cross-Modality Masked Autoencoders for Region-Aware Audio-Visual Pre-Training [[2024 CVPR](https://openaccess.thecvf.com/content/CVPR2024/papers/Guo_CrossMAE_Cross-Modality_Masked_Autoencoders_for_Region-Aware_Audio-Visual_Pre-Training_CVPR_2024_paper.pdf)]  
Customized Multiple Clustering via Multi-Modal Subspace Proxy Learning  
Extending Multi-modal Contrastive Representations [[NeurIPS 2024](https://arxiv.org/pdf/2310.08884)]  
UMFC: Unsupervised Multi-Domain Feature Calibration for Vision-Language Models [[2024](https://arxiv.org/pdf/2411.06921)]  
DPA: Dual Prototypes Alignment for Unsupervised Adaptation of Vision-Language Models [[2024](https://arxiv.org/pdf/2408.08855)]  
ImageResolutionandText Label Are Important Things for Large Multi-modal Models [[CVPR 2024 Highlight](https://arxiv.org/pdf/2311.06607)]

## Cross Attention
Cross Attention Network for Few-shot Classification [[2019](https://proceedings.neurips.cc/paper_files/paper/2019/file/01894d6f048493d2cacde3c579c315a3-Paper.pdf)]  
CAT: Cross Attention in Vision Transformer [[2021](https://arxiv.org/pdf/2106.05786)]  

## zero few shot
Laplacian Regularized Few-Shot Learning [[2021](https://proceedings.mlr.press/v119/ziko20a/ziko20a.pdf)]   
Parameterless Transductive Feature Re-representation for Few-Shot Learning [[ICML 2021](https://proceedings.mlr.press/v139/cui21a/cui21a.pdf)]  
Class-Aware Patch Embedding Adaptation for Few-Shot Image Classification 
[[ICCV 2023](https://openaccess.thecvf.com/content/ICCV2023/papers/Hao_Class-Aware_Patch_Embedding_Adaptation_for_Few-Shot_Image_Classification_ICCV_2023_paper.pdf)]  
Transductive Few-shot Learning with Prototype-based Label Propagation by Iterative Graph Refinement [[2023 CVPR](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhu_Transductive_Few-Shot_Learning_With_Prototype-Based_Label_Propagation_by_Iterative_Graph_CVPR_2023_paper.pdf)]  
Transductive Zero-Shot and Few-Shot CLIP [[2024 CVPR](https://openaccess.thecvf.com/content/CVPR2024/papers/Martin_Transductive_Zero-Shot_and_Few-Shot_CLIP_CVPR_2024_paper.pdf)]
Boosting Vision-Language Models with Transduction [[ 2024 ](https://arxiv.org/pdf/2406.01837)]  
Selective Vision-Language Subspace Projection for Few-shot CLIP [[2024](https://arxiv.org/pdf/2407.16977)]  
Interpreting and Analyzing CLIPâ€™s Zero-Shot Image Classification via Mutual Knowledge [[2024](https://arxiv.org/pdf/2410.13016)]  
UNEM: UNrolled Generalized EM for Transductive Few-Shot Learning [[2024](https://arxiv.org/pdf/2412.16739)]

## Model Merging
EDITING MODELS WITH TASK ARITHMETIC [[ICLR 2023](https://arxiv.org/pdf/2212.04089)]  
Parameter Competition Balancing for Model Merging [[NeurIPS 2024](https://arxiv.org/pdf/2410.02396)]  
BRAVE: Broadening the visual encoding of vision-language models [[ECCV 2024](https://brave-vlms.epfl.ch/)]  
EMR-MERGING: Tuning-Free High-Performance Model Merging [[ 2024 ](https://arxiv.org/pdf/2405.17461)]

## Representation Learning
TPTE: Text-guided Patch Token Exploitation for Unsupervised Fine-Grained Representation Learning [[ACM Trans](https://dl.acm.org/doi/pdf/10.1145/3673657)]  
Disentangled Representation Learning [[2024](https://arxiv.org/pdf/2211.11695)]  

## Instance Retrieval
Cluster-Aware Similarity Diffusion for Instance Retrieval [[2024](https://arxiv.org/pdf/2406.02343)]

## semantic segmentation
Vision Transformers for Dense Prediction (DPT)[[2021 ICCV](https://arxiv.org/abs/2103.13413v1)]  
Language-driven Semantic Segmentation [[2022 ICLR](https://arxiv.org/pdf/2201.03546)]  
Extract Free Dense Labels from CLIP (MASK CLIP) [[2022 ECCV](https://arxiv.org/pdf/2112.01071)]   
ZegCLIP: Towards Adapting CLIP for Zero-shot Semantic Segmentation [[2023 CVPR](https://arxiv.org/pdf/2212.03588)]  
Explore the Potential of CLIP for Training-Free Open Vocabulary Semantic Segmentation [[2024 ECCV](https://arxiv.org/pdf/2407.08268)]  
ProxyCLIP: Proxy Attention Improves CLIP for Open-Vocabulary Segmentation [[ECCV](https://arxiv.org/pdf/2408.04883)]  
SCLIP: Rethinking Self-Attention for Dense Vision-Language Inference [[ECCV 2024](https://arxiv.org/pdf/2312.01597)]  
Revisit Anything: Visual Place Recognition via Image Segment Retrieval [[2024](https://arxiv.org/pdf/2409.18049)]  
Pay Attention to Your Neighbours: Training-Free Open-Vocabulary Semantic Segmentation [[2024](https://arxiv.org/pdf/2404.08181)]  
ClearCLIP: Decomposing CLIP Representations for Dense Vision-Language Inference[[ECCV 2024](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/06346.pdf)]  
BRIDGING THE GAP TO REAL-WORLD OBJECTCENTRIC LEARNING [[2023](https://arxiv.org/pdf/2209.14860)]  
DINOv2 Meets Text: A Unified Framework for Image- and Pixel-Level Vision-Language Alignment [[2024](https://arxiv.org/pdf/2412.16334)]

## Clustering
Clustering and Projected Clustering with Adaptive Neighbors [[2014 KDD](https://matlabtools.com/wp-content/uploads/p1004.pdf)]  
The Constrained Laplacian Rank Algorithm for Graph-Based Clustering [[2016 AAAI](https://ojs.aaai.org/index.php/AAAI/article/download/10302/10161)]  
TOWARDS CALIBRATED DEEP CLUSTERING NETWORK[[2025](https://openreview.net/pdf?id=JvH4jDDcG3)]  

## Optimal Transportation
Unsupervised Learning of Visual Features by Contrasting Cluster Assignments [[NeurIPS 2020](https://arxiv.org/pdf/2006.09882)]  
Towards Interpretable Deep Metric Learning with Structural Matching [[ICCV 2021](https://openaccess.thecvf.com/content/ICCV2021/papers/Zhao_Towards_Interpretable_Deep_Metric_Learning_With_Structural_Matching_ICCV_2021_paper.pdf)]  
Optimal Transport Aggregation for Visual Place Recognition [[CVPR 2024](https://arxiv.org/abs/2311.15937)]  
Data Selection via Optimal Control for Language Models [[]()]
